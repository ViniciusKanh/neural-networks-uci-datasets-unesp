# ğŸ§  Trabalho 2 â€“ ComputaÃ§Ã£o Inspirada pela Natureza (2024)

Este repositÃ³rio contÃ©m a implementaÃ§Ã£o e anÃ¡lise dos experimentos do Trabalho 2 da disciplina de **ComputaÃ§Ã£o Inspirada pela Natureza**, com foco em **redes neurais artificiais** aplicadas a problemas clÃ¡ssicos de classificaÃ§Ã£o.

## ğŸ“š DescriÃ§Ã£o Geral

O trabalho Ã© dividido em trÃªs exercÃ­cios, cada um com foco em um dataset e tÃ©cnica especÃ­fica de aprendizado supervisionado:

| ExercÃ­cio | Dataset              | TÃ©cnica Utilizada              | Objetivo                             |
|----------|----------------------|-------------------------------|--------------------------------------|
| 1        | Iris                 | Perceptron One-vs-Rest (OvR)  | ClassificaÃ§Ã£o multiclasse linear     |
| 2        | Wine                 | Perceptron One-vs-Rest (OvR)  | AvaliaÃ§Ã£o de separabilidade linear   |
| 3        | Breast Cancer (Wisconsin) | MLP (com e sem Dropout) | ComparaÃ§Ã£o entre arquiteturas de redes neurais |

---

## ğŸ“¦ Tecnologias Utilizadas

- Python 3.11
- Google Colab / Jupyter
- Bibliotecas:
  - `numpy`, `pandas`, `matplotlib`, `scikit-learn`
  - `tensorflow`, `keras`

---

## ğŸ§ª Estrutura dos Arquivos

- `Trabalho 2.ipynb` â€“ Notebook com todos os cÃ³digos, grÃ¡ficos, interpretaÃ§Ãµes e resultados.
- `Trabalho 2.pdf` â€“ RelatÃ³rio final exportado com comentÃ¡rios cientÃ­ficos em Markdown.
- `README.md` â€“ Este documento com instruÃ§Ãµes e descriÃ§Ã£o do projeto.

---

## ğŸ” Resultados Obtidos

### ğŸ”¸ Perceptron â€“ Iris
- **Treinamento**: 82.86%  
- **ValidaÃ§Ã£o**: 59.09%  
- **Teste**: 82.61%  

### ğŸ”¸ Perceptron â€“ Wine
- **Treinamento**: 100.00%  
- **ValidaÃ§Ã£o**: 96.30%  
- **Teste**: 88.89%  

### ğŸ”¸ Redes Neurais â€“ Breast Cancer
| Arquitetura                 | AcurÃ¡cia no Teste |
|----------------------------|-------------------|
| MLP (1 camada oculta)      | 96.51%            |
| MLP (2 camadas ocultas)    | 96.51%            |
| MLP + Dropout              | **97.67%**        |

---

## ğŸ“Œ ConclusÃ£o

O projeto demonstrou que modelos simples como o Perceptron podem ser eficientes em problemas linearmente separÃ¡veis, mas redes neurais multicamadas (MLP) oferecem maior capacidade de generalizaÃ§Ã£o e desempenho em cenÃ¡rios mais complexos. A regularizaÃ§Ã£o com Dropout foi eficaz na reduÃ§Ã£o do overfitting.

---

## âœï¸ Autor

**Vinicius de Souza Santos**  
Estudante de Engenharia da ComputaÃ§Ã£o  
IFSP â€“ Instituto Federal de SÃ£o Paulo  
2024â€“2025

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a [MIT License](LICENSE).
